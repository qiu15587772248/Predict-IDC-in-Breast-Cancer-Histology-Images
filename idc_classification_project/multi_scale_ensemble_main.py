import torch
import numpy as np
import os
import json
import warnings

# é¡¹ç›®æ¨¡å—å¯¼å…¥
from . import configs
from . import data_utils
from . import train_utils
from .ResNet_model import SimpleResNetClassifier
from .efficientnet_model import EfficientNetB0
from .multi_scale_ensemble import MultiScaleEnsembleModel
from .train_utils import seed_everything  

# åœ¨è„šæœ¬æ—©æœŸæŠ‘åˆ¶ albumentations çš„ç‰ˆæœ¬æ£€æŸ¥è­¦å‘Š
warnings.filterwarnings("ignore", message="Error fetching version info", module="albumentations.check_version")


def evaluate_multi_scale_ensemble(ensemble_model, test_loader_50, test_loader_224, 
                                 device, threshold=0.5):
    """
    è¯„ä¼°å¤šå°ºåº¦é›†æˆæ¨¡å‹
    """
    ensemble_model.eval()
    all_labels = []
    all_probs = []
    
    with torch.no_grad():
        for (inputs_50, labels_50), (inputs_224, labels_224) in zip(test_loader_50, test_loader_224):
            # å‡†å¤‡å¤šå°ºåº¦è¾“å…¥
            inputs = {
                '50x50': inputs_50.to(device),
                '224x224': inputs_224.to(device)
            }
            
            with torch.amp.autocast(device_type='cuda'):
                probs = ensemble_model.predict_proba(inputs)[:, 1]  
            
            all_labels.extend(labels_50.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())
    
    # è®¡ç®—å„é¡¹æŒ‡æ ‡
    from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                               f1_score, roc_auc_score, confusion_matrix)
    
    predictions = (np.array(all_probs) >= threshold).astype(int)
    
    accuracy = accuracy_score(all_labels, predictions)
    precision = precision_score(all_labels, predictions, zero_division=0)
    recall = recall_score(all_labels, predictions, zero_division=0)
    f1 = f1_score(all_labels, predictions, zero_division=0)
    
    if len(np.unique(all_labels)) >= 2:
        auc = roc_auc_score(all_labels, all_probs)
    else:
        auc = 0.0
    
    cm = confusion_matrix(all_labels, predictions, labels=[0, 1])
    
    # è®¡ç®—ç‰¹å¼‚æ€§
    specificity = 0.0
    if cm.shape == (2, 2):
        tn, fp, fn, tp = cm.ravel()
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'auc': auc,
        'specificity': specificity,
        'confusion_matrix': cm,
        'threshold': threshold,
        'all_labels': all_labels,
        'all_probs': all_probs
    }


def run_multi_scale_ensemble_pipeline():
    """
    æ‰§è¡Œå¤šå°ºåº¦é›†æˆæ¨¡å‹çš„å®Œæ•´æµç¨‹
    """
    # è®¾ç½®éšæœºç§å­
    train_utils.seed_everything()
    
    # é…ç½®
    device = train_utils.get_device()
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    

    _script_path = os.path.abspath(__file__)
    # _script_directory æ˜¯è„šæœ¬æ‰€åœ¨çš„ç›®å½• 
    _script_directory = os.path.dirname(_script_path)
    # _project_root æ˜¯é¡¹ç›®æ ¹ç›®å½• 
    _project_root = os.path.dirname(_script_directory)
    
    # æ¨¡å‹è·¯å¾„ã€‚è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹è¿™äº›è·¯å¾„
    RESNET_MODEL_PATH = os.path.normpath(os.path.join(
        _project_root,
        'output_resnet_focal_alpha0.7_gamma3_lrsched_albu',
        'models',
        'best_model.pth'
    ))
    EFFICIENTNET_MODEL_PATH = os.path.normpath(os.path.join(
        _project_root,
        'output_efficientnet_optimized',
        'models',
        'best_model.pth'
    ))
    
    # è¾“å‡ºç›®å½•
    OUTPUT_DIR = 'output_multi_scale_ensemble'
    VISUALIZATION_DIR = os.path.join(OUTPUT_DIR, 'visualizations')
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    os.makedirs(VISUALIZATION_DIR, exist_ok=True)
    
    print("--- åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹ ---")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(RESNET_MODEL_PATH):
        print(f"é”™è¯¯: ResNetæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {RESNET_MODEL_PATH}")
        print("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶è·¯å¾„æ­£ç¡®")
        return
    
    if not os.path.exists(EFFICIENTNET_MODEL_PATH):
        print(f"é”™è¯¯: EfficientNetæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {EFFICIENTNET_MODEL_PATH}")
        print("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶è·¯å¾„æ­£ç¡®")
        return
    
    # åŠ è½½ResNetæ¨¡å‹
    resnet_model = SimpleResNetClassifier(num_classes=2, pretrained=False)
    try:
        resnet_model.load_state_dict(torch.load(RESNET_MODEL_PATH, map_location=device, weights_only=True))
    except:
        resnet_model.load_state_dict(torch.load(RESNET_MODEL_PATH, map_location=device, weights_only=False))
    resnet_model.to(device)
    resnet_model.eval()
    print("ResNetæ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # åŠ è½½EfficientNetæ¨¡å‹
    efficientnet_model = EfficientNetB0(num_classes=2, pretrained=False)
    try:
        efficientnet_model.load_state_dict(torch.load(EFFICIENTNET_MODEL_PATH, map_location=device, weights_only=True))
    except:
        efficientnet_model.load_state_dict(torch.load(EFFICIENTNET_MODEL_PATH, map_location=device, weights_only=False))
    efficientnet_model.to(device)
    efficientnet_model.eval()
    print("EfficientNetæ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # å‡†å¤‡æ•°æ®åŠ è½½å™¨
    print("\n--- å‡†å¤‡å¤šå°ºåº¦æ•°æ®åŠ è½½å™¨ ---")
    
    # ä¸ºä¸¤ä¸ªæ¨¡å‹è®¾ç½®ç»Ÿä¸€çš„æ‰¹æ¬¡å¤§å°ï¼Œä»¥é¿å…é›†æˆæ—¶ç»´åº¦ä¸åŒ¹é…é—®é¢˜
    # é€‰æ‹©è¾ƒå°æ¨¡å‹çš„æ‰¹æ¬¡å¤§å°ï¼ˆé€šå¸¸æ˜¯é’ˆå¯¹è¾ƒå¤§è¾“å…¥å°ºå¯¸çš„æ¨¡å‹ï¼‰
    UNIFIED_BATCH_SIZE_FOR_ENSEMBLE = 32 
    print(f"ä¸ºé›†æˆæ¨¡å‹çš„æ•°æ®åŠ è½½å™¨è®¾ç½®ç»Ÿä¸€æ‰¹æ¬¡å¤§å°: {UNIFIED_BATCH_SIZE_FOR_ENSEMBLE}")

    # ResNetæ•°æ®åŠ è½½å™¨ (50x50)
    print("å‡†å¤‡50x50è¾“å…¥çš„æ•°æ®åŠ è½½å™¨...")
    train_loader_50, val_loader_50, test_loader_50 = data_utils.prepare_dataloaders(
        data_dir=configs.BASE_DATA_DIR,
        batch_size=UNIFIED_BATCH_SIZE_FOR_ENSEMBLE,  # ä½¿ç”¨ç»Ÿä¸€çš„æ‰¹æ¬¡å¤§å°
        test_size=getattr(configs, 'TEST_SPLIT_RATIO', 0.2),
        val_size=getattr(configs, 'VAL_SPLIT_RATIO', 0.1),
        random_state=getattr(configs, 'RANDOM_SEED', 42),
        patch_size=50,  # ResNetè¾“å…¥å°ºå¯¸
        num_workers=getattr(configs, 'NUM_DATALOADER_WORKERS', 8)
    )
    
    # EfficientNetæ•°æ®åŠ è½½å™¨ (224x224)
    print("å‡†å¤‡224x224è¾“å…¥çš„æ•°æ®åŠ è½½å™¨...")
    train_loader_224, val_loader_224, test_loader_224 = data_utils.prepare_dataloaders(
        data_dir=configs.BASE_DATA_DIR,
        batch_size=UNIFIED_BATCH_SIZE_FOR_ENSEMBLE,  # ä½¿ç”¨ç»Ÿä¸€çš„æ‰¹æ¬¡å¤§å°
        test_size=getattr(configs, 'TEST_SPLIT_RATIO', 0.2),
        val_size=getattr(configs, 'VAL_SPLIT_RATIO', 0.1),
        random_state=getattr(configs, 'RANDOM_SEED', 42),
        patch_size=224,  # EfficientNetè¾“å…¥å°ºå¯¸
        num_workers=getattr(configs, 'NUM_DATALOADER_WORKERS', 8)
    )
    
    if val_loader_50 is None or test_loader_50 is None or val_loader_224 is None or test_loader_224 is None:
        print("é”™è¯¯ï¼šä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®åŠ è½½å™¨æœªèƒ½æˆåŠŸåˆ›å»ºã€‚è¯·æ£€æŸ¥æ•°æ®è·¯å¾„ã€é…ç½®å’Œ prepare_dataloaders å‡½æ•°çš„è¾“å‡ºã€‚")
        return

    print(f"éªŒè¯é›†æ ·æœ¬æ•° (50x50): {len(val_loader_50.dataset) if val_loader_50 and hasattr(val_loader_50, 'dataset') else 'N/A'}")
    print(f"æµ‹è¯•é›†æ ·æœ¬æ•° (50x50): {len(test_loader_50.dataset) if test_loader_50 and hasattr(test_loader_50, 'dataset') else 'N/A'}")
    print(f"éªŒè¯é›†æ ·æœ¬æ•° (224x224): {len(val_loader_224.dataset) if val_loader_224 and hasattr(val_loader_224, 'dataset') else 'N/A'}")
    print(f"æµ‹è¯•é›†æ ·æœ¬æ•° (224x224): {len(test_loader_224.dataset) if test_loader_224 and hasattr(test_loader_224, 'dataset') else 'N/A'}")
    
    # åˆ›å»ºå¤šå°ºåº¦é›†æˆæ¨¡å‹
    print("\n--- åˆ›å»ºå¤šå°ºåº¦é›†æˆæ¨¡å‹ ---")
    
    models_config = [
        {
            'model': resnet_model,
            'input_size': (50, 50),
            'name': 'ResNet18'
        },
        {
            'model': efficientnet_model,
            'input_size': (224, 224),
            'name': 'EfficientNet-B0'
        }
    ]
    
    # ä½¿ç”¨ç‰¹å¼‚æ€§ä¼˜åŒ–çš„é›†æˆæ–¹æ³•
    ensemble_model = MultiScaleEnsembleModel(
        models_config=models_config,
        ensemble_method='specificity_focused',  # ä½¿ç”¨ç‰¹å¼‚æ€§ä¼˜åŒ–çš„é›†æˆæ–¹æ³•
        initial_weights=None  # è®©æ¨¡å‹è‡ªåŠ¨è®¾ç½®åˆå§‹æƒé‡
    )
    ensemble_model.to(device)
    
    # åœ¨éªŒè¯é›†ä¸Šä¼˜åŒ–æƒé‡å’Œé˜ˆå€¼
    print("\n--- åœ¨éªŒè¯é›†ä¸Šä¼˜åŒ–é›†æˆæƒé‡å’Œé˜ˆå€¼ ---")
    print("æ­£åœ¨æœç´¢æœ€ä½³æƒé‡ç»„åˆå’Œé˜ˆå€¼ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...")
    
    best_weights, best_threshold, best_metrics = ensemble_model.optimize_for_metrics(
        val_loader_50=val_loader_50,
        val_loader_224=val_loader_224,
        device=device,
        min_specificity=0.95,  # ç‰¹å¼‚æ€§è¦æ±‚
        min_sensitivity=0.85   # æ•æ„Ÿæ€§è¦æ±‚
    )
    
    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
    print("\n--- åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°å¤šå°ºåº¦é›†æˆæ¨¡å‹ ---")
    test_results = evaluate_multi_scale_ensemble(
        ensemble_model, test_loader_50, test_loader_224, device, threshold=best_threshold
    )
    
    print(f"\næµ‹è¯•é›†ç»“æœ (é˜ˆå€¼: {test_results['threshold']:.3f}):")
    print(f"  å‡†ç¡®ç‡: {test_results['accuracy']:.4f}")
    print(f"  ç²¾ç¡®ç‡: {test_results['precision']:.4f}")
    print(f"  å¬å›ç‡ (æ•æ„Ÿæ€§): {test_results['recall']:.4f}")
    print(f"  F1åˆ†æ•°: {test_results['f1']:.4f}")
    print(f"  AUC: {test_results['auc']:.4f}")
    print(f"  ç‰¹å¼‚æ€§: {test_results['specificity']:.4f}")
    print(f"  æ··æ·†çŸ©é˜µ:\n{test_results['confusion_matrix']}")
    
    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°é¡¹ç›®è¦æ±‚
    print("\n--- æ€§èƒ½æŒ‡æ ‡æ£€æŸ¥ ---")
    requirements_met = True
    
    if test_results['accuracy'] >= 0.90:
        print(f"âœ“ å‡†ç¡®ç‡: {test_results['accuracy']:.4f} (è¦æ±‚ â‰¥ 0.90)")
    else:
        print(f"âœ— å‡†ç¡®ç‡: {test_results['accuracy']:.4f} (è¦æ±‚ â‰¥ 0.90)")
        requirements_met = False
    
    if test_results['auc'] >= 0.95:
        print(f"âœ“ AUC: {test_results['auc']:.4f} (è¦æ±‚ â‰¥ 0.95)")
    else:
        print(f"âœ— AUC: {test_results['auc']:.4f} (è¦æ±‚ â‰¥ 0.95)")
        requirements_met = False
    
    if test_results['specificity'] >= 0.95:
        print(f"âœ“ ç‰¹å¼‚æ€§: {test_results['specificity']:.4f} (è¦æ±‚ â‰¥ 0.95)")
    else:
        print(f"âœ— ç‰¹å¼‚æ€§: {test_results['specificity']:.4f} (è¦æ±‚ â‰¥ 0.95)")
        requirements_met = False
    
    if test_results['recall'] >= 0.85:
        print(f"âœ“ æ•æ„Ÿæ€§: {test_results['recall']:.4f} (è¦æ±‚ â‰¥ 0.85)")
    else:
        print(f"âœ— æ•æ„Ÿæ€§: {test_results['recall']:.4f} (è¦æ±‚ â‰¥ 0.85)")
        requirements_met = False
    
    if requirements_met:
        print("\nğŸ‰ æ­å–œï¼å¤šå°ºåº¦é›†æˆæ¨¡å‹æ»¡è¶³æ‰€æœ‰é¡¹ç›®è¦æ±‚ï¼")
    else:
        print("\nâš ï¸ å¤šå°ºåº¦é›†æˆæ¨¡å‹å°šæœªæ»¡è¶³æ‰€æœ‰è¦æ±‚ã€‚")
    
    # ä¿å­˜ç»“æœ
    results_dict = {
        'ensemble_method': 'specificity_focused',
        'model_weights': {
            'resnet': float(best_weights[0]),
            'efficientnet': float(best_weights[1])
        },
        'best_threshold': float(best_threshold),
        'validation_metrics': {
            'f1': float(best_metrics['f1']),
            'specificity': float(best_metrics['specificity']),
            'sensitivity': float(best_metrics['sensitivity']),
            'auc': float(best_metrics['auc']),
            'accuracy': float(best_metrics['accuracy'])
        },
        'test_results': {
            'accuracy': float(test_results['accuracy']),
            'precision': float(test_results['precision']),
            'recall': float(test_results['recall']),
            'f1': float(test_results['f1']),
            'auc': float(test_results['auc']),
            'specificity': float(test_results['specificity']),
            'confusion_matrix': test_results['confusion_matrix'].tolist()
        },
        'requirements_met': requirements_met
    }
    
    with open(os.path.join(OUTPUT_DIR, 'multi_scale_ensemble_results.json'), 'w') as f:
        json.dump(results_dict, f, indent=4, ensure_ascii=False)
    
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {os.path.join(OUTPUT_DIR, 'multi_scale_ensemble_results.json')}")
    
    # ç»˜åˆ¶ROCæ›²çº¿å’ŒPRæ›²çº¿
    print("\n--- ç»˜åˆ¶æ€§èƒ½æ›²çº¿ ---")
    
    # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡å­—ä½“
    train_utils.set_chinese_font_for_matplotlib_local()
    
    train_utils.plot_roc_curve(
        test_results['all_labels'], 
        test_results['all_probs'], 
        save_dir=VISUALIZATION_DIR, 
        threshold=best_threshold
    )
    train_utils.plot_pr_curve(
        test_results['all_labels'], 
        test_results['all_probs'], 
        save_dir=VISUALIZATION_DIR, 
        threshold=best_threshold
    )
    
    # ç»˜åˆ¶é›†æˆæ¨¡å‹æ€§èƒ½æ€»ç»“å›¾
    visualize_ensemble_results(results_dict, VISUALIZATION_DIR)
    
    # ä¿å­˜é›†æˆæ¨¡å‹
    ensemble_state = {
        'models_config': [
            {'name': config['name'], 'input_size': config['input_size']} 
            for config in models_config
        ],
        'weights': best_weights,
        'threshold': best_threshold,
        'ensemble_method': 'specificity_focused'
    }
    
    torch.save(ensemble_state, os.path.join(OUTPUT_DIR, 'ensemble_model_state.pth'))
    print(f"\né›†æˆæ¨¡å‹çŠ¶æ€å·²ä¿å­˜åˆ°: {os.path.join(OUTPUT_DIR, 'ensemble_model_state.pth')}")
    
    print("\n--- å¤šå°ºåº¦é›†æˆæ¨¡å‹è¯„ä¼°å®Œæˆ ---")


def visualize_ensemble_results(results_dict, save_dir):
    """
    å¯è§†åŒ–é›†æˆæ¨¡å‹çš„ç»“æœï¼ŒåŒ…æ‹¬æ¨¡å‹æƒé‡å’Œæ€§èƒ½å¯¹æ¯”
    """
    import matplotlib.pyplot as plt
    import matplotlib.font_manager as fm
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    font_names = ['SimHei', 'Microsoft YaHei', 'FangSong', 'KaiTi', 'sans-serif']
    for font_name in font_names:
        try:
            font_prop = fm.FontProperties(family=font_name)
            fm.findfont(font_prop, fallback_to_default=False, fontext='ttf')
            plt.rcParams['font.family'] = font_name
            print(f"é›†æˆæ¨¡å‹å¯è§†åŒ–ä½¿ç”¨å­—ä½“: {font_name}")
            break
        except Exception:
            continue
    plt.rcParams['axes.unicode_minus'] = False
    
    # åˆ›å»ºå›¾å½¢
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # 1. æ¨¡å‹æƒé‡é¥¼å›¾
    ax1 = axes[0, 0]
    weights = [results_dict['model_weights']['resnet'], results_dict['model_weights']['efficientnet']]
    labels = ['ResNet18\n(50Ã—50)', 'EfficientNet-B0\n(224Ã—224)']
    colors = ['#ff9999', '#66b3ff']
    ax1.pie(weights, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
    ax1.set_title('æ¨¡å‹æƒé‡åˆ†é…', fontsize=14, fontweight='bold')
    
    # 2. æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”æŸ±çŠ¶å›¾
    ax2 = axes[0, 1]
    metrics = ['å‡†ç¡®ç‡', 'ç²¾ç¡®ç‡', 'å¬å›ç‡', 'F1åˆ†æ•°', 'AUC', 'ç‰¹å¼‚æ€§']
    values = [
        results_dict['test_results']['accuracy'],
        results_dict['test_results']['precision'],
        results_dict['test_results']['recall'],
        results_dict['test_results']['f1'],
        results_dict['test_results']['auc'],
        results_dict['test_results']['specificity']
    ]
    bars = ax2.bar(metrics, values, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b'])
    ax2.set_ylim(0, 1.1)
    ax2.set_ylabel('åˆ†æ•°', fontsize=12)
    ax2.set_title('é›†æˆæ¨¡å‹æ€§èƒ½æŒ‡æ ‡', fontsize=14, fontweight='bold')
    ax2.grid(True, axis='y', alpha=0.3)
    
    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
    for bar, value in zip(bars, values):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{value:.3f}', ha='center', va='bottom', fontsize=10)
    
    # 3. æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾
    ax3 = axes[1, 0]
    cm = results_dict['test_results']['confusion_matrix']
    im = ax3.imshow(cm, interpolation='nearest', cmap='Blues')
    ax3.set_xticks([0, 1])
    ax3.set_yticks([0, 1])
    ax3.set_xticklabels(['é¢„æµ‹: éIDC', 'é¢„æµ‹: IDC'])
    ax3.set_yticklabels(['å®é™…: éIDC', 'å®é™…: IDC'])
    ax3.set_xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)
    ax3.set_ylabel('å®é™…æ ‡ç­¾', fontsize=12)
    ax3.set_title('æ··æ·†çŸ©é˜µ', fontsize=14, fontweight='bold')
    
    # åœ¨æ··æ·†çŸ©é˜µä¸­æ·»åŠ æ•°å€¼
    for i in range(2):
        for j in range(2):
            text = ax3.text(j, i, str(cm[i][j]), ha="center", va="center",
                           color="white" if cm[i][j] > cm.max()/2 else "black", fontsize=12)
    
    # 4. ç›®æ ‡è¾¾æˆæƒ…å†µ
    ax4 = axes[1, 1]
    ax4.axis('off')
    
    # åˆ›å»ºè¡¨æ ¼æ•°æ®
    requirements = [
        ['æŒ‡æ ‡', 'è¦æ±‚', 'å®é™…å€¼', 'çŠ¶æ€'],
        ['å‡†ç¡®ç‡', 'â‰¥ 90%', f"{results_dict['test_results']['accuracy']:.1%}", 
         'âœ“' if results_dict['test_results']['accuracy'] >= 0.90 else 'âœ—'],
        ['AUC', 'â‰¥ 95%', f"{results_dict['test_results']['auc']:.1%}", 
         'âœ“' if results_dict['test_results']['auc'] >= 0.95 else 'âœ—'],
        ['ç‰¹å¼‚æ€§', 'â‰¥ 95%', f"{results_dict['test_results']['specificity']:.1%}", 
         'âœ“' if results_dict['test_results']['specificity'] >= 0.95 else 'âœ—'],
        ['æ•æ„Ÿæ€§', 'â‰¥ 85%', f"{results_dict['test_results']['recall']:.1%}", 
         'âœ“' if results_dict['test_results']['recall'] >= 0.85 else 'âœ—']
    ]
    
    # åˆ›å»ºè¡¨æ ¼
    table = ax4.table(cellText=requirements[1:], colLabels=requirements[0],
                     cellLoc='center', loc='center', colWidths=[0.3, 0.2, 0.3, 0.2])
    table.auto_set_font_size(False)
    table.set_fontsize(11)
    table.scale(1, 2)
    
    # è®¾ç½®è¡¨æ ¼æ ·å¼
    for i in range(len(requirements)):
        for j in range(len(requirements[0])):
            cell = table[(i, j)]
            if i == 0:  # è¡¨å¤´
                cell.set_facecolor('#4CAF50')
                cell.set_text_props(weight='bold', color='white')
            else:
                if j == 3:  # çŠ¶æ€åˆ—
                    if requirements[i][j] == 'âœ“':
                        cell.set_facecolor('#c8e6c9')
                    else:
                        cell.set_facecolor('#ffcdd2')
    
    ax4.set_title('é¡¹ç›®è¦æ±‚è¾¾æˆæƒ…å†µ', fontsize=14, fontweight='bold', pad=20)
    
    # è°ƒæ•´å­å›¾é—´è·
    plt.tight_layout()
    
    # ä¿å­˜å›¾å½¢
    save_path = os.path.join(save_dir, 'ensemble_performance_summary.png')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"é›†æˆæ¨¡å‹æ€§èƒ½æ€»ç»“å›¾å·²ä¿å­˜åˆ°: {save_path}")
    plt.close()


if __name__ == '__main__':
    run_multi_scale_ensemble_pipeline() 